{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T08:40:55.129715Z",
     "start_time": "2019-03-06T08:40:53.448575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from rosette.api import API, DocumentParameters, RosetteException\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:44:32.542755Z",
     "start_time": "2019-03-07T15:44:32.482886Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load links/utils.py\n",
    "QUERY_DICT = {'Organization Founded By^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          ?item wdt:P112 wd:%s.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                           ],\n",
    "              'Organization Founded By':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P112 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                        ],\n",
    "              'Organization Headquarters':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P159 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                          ],\n",
    "              'Organization Subsidiary Of^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P355 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                              ],\n",
    "              'Organization Subsidiary Of':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          ?item wdt:P355 wd:%s.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                           ],\n",
    "              'Organization top employees':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P169 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\", # CEO\n",
    "                                            \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P488 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\" # Chairperson\n",
    "                                            ],\n",
    "              'Person Employee or Member of^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          ?item wdt:P108 wd:%s.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\",\n",
    "                                            \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P527 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\" \n",
    "                                                ],\n",
    "              'Person Employee or Member of':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P108 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\",\n",
    "                                              \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P463 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"## member of ---> Band Members\n",
    "                                            ],\n",
    "              'Person Place of Birth':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P19 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                      ],\n",
    "              'Person Current and Past Location of Residence':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P551 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                                              ],\n",
    "              'Person Parents':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P22 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\", #Father\n",
    "                                \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P25 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\", #Mother\n",
    "                                \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P1038 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\" #Relative (Adopted Parents?)\n",
    "                                # Shall we include stepparents??\n",
    "                               ],\n",
    "              'Person Parents^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P40 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                  ],\n",
    "              'Person Siblings':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P3373 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                ],\n",
    "              'Person Spouse':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P26 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                              ],\n",
    "              'Citizen of':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P27 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                           ],\n",
    "              'Educated at':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P69 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                            ]\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON   \n",
    "from rosette.api import API, DocumentParameters, RosetteException\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "import requests\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from threading import Lock\n",
    "import os, sys\n",
    "import threading\n",
    "from threading import Thread\n",
    "import time\n",
    "import queue\n",
    "\n",
    "class Utils:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.id_dict = {}\n",
    "        self.lock = Lock()\n",
    "        self.load_dict()\n",
    "        \n",
    "    \n",
    "    def __del__(self):\n",
    "        self.save_dict()\n",
    "\n",
    "    def get_id(self, message, dict_to_use=None):\n",
    "#         if dict_to_use:\n",
    "#             dict_to_use = dict_to_use\n",
    "#         else:\n",
    "#             global id_dict\n",
    "#             dict_to_use = id_dict\n",
    "    \n",
    "        if message in self.id_dict:\n",
    "            return self.id_dict[message]\n",
    "        else:\n",
    "            API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "            query = message\n",
    "            params = {\n",
    "                'action': 'wbsearchentities',\n",
    "                'format': 'json',\n",
    "                'language': 'en',\n",
    "                'search': query\n",
    "            }\n",
    "            r = requests.get(API_ENDPOINT, params = params)\n",
    "            try:\n",
    "                with self.lock:\n",
    "                    self.id_dict[message] = r.json()['search'][0]['id']\n",
    "                return self.id_dict[message]\n",
    "            except Exception:\n",
    "                return -1 #The id doesn't exist\n",
    "\n",
    "\n",
    "    def id_to_name(self, eid):\n",
    "#         if dict_to_use:\n",
    "#             dict_to_use = dict_to_use\n",
    "#         else:\n",
    "#             global id_dict\n",
    "#             dict_to_use = id_dict\n",
    "\n",
    "        if eid in self.id_dict.values():\n",
    "            return [key for key, value in self.id_dict.items() if value == eid][0]\n",
    "        else:\n",
    "            API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "            query = eid\n",
    "            params = {\n",
    "                'action': 'wbsearchentities',\n",
    "                'format': 'json',\n",
    "                'language': 'en',\n",
    "                'search': query\n",
    "            }\n",
    "            r = requests.get(API_ENDPOINT, params = params)\n",
    "            try:\n",
    "                with self.lock:\n",
    "                    self.id_dict[ r.json()['search'][0]['label'] ] = r.json()['search'][0]['id']\n",
    "                return r.json()['search'][0]['label']\n",
    "            except Exception:\n",
    "                return -1 #The id doesn't exist\n",
    "\n",
    "\n",
    "    def get_results(self, query, value, endpoint_url=\"https://query.wikidata.org/sparql\"):\n",
    "        sparql = SPARQLWrapper(endpoint_url)\n",
    "        sparql.setQuery(query%value)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        return sparql.query().convert()\n",
    "\n",
    "\n",
    "    def ground_truth(self, relation, subject, debug=False):\n",
    "        global QUERY_DICT\n",
    "        results = []\n",
    "        gt = []\n",
    "        try:\n",
    "            results = [self.get_results(query, self.get_id(subject)) for query in QUERY_DICT[relation]]\n",
    "            for result in results:\n",
    "                for r in result[\"results\"][\"bindings\"]:\n",
    "                    gt.append(r['itemLabel']['value'])\n",
    "        except:\n",
    "            if debug:\n",
    "                print (relation, subject)\n",
    "        return gt\n",
    "\n",
    "    def add_ground_truth(self, df, debug=False):\n",
    "        if df.empty:\n",
    "            return df\n",
    "        if debug:\n",
    "            print (df)\n",
    "        df = df.reset_index()\n",
    "        df['Pseudo Ground Truth'] = df.apply(lambda row: self.ground_truth(row['Relationship'], row['Subject']), axis=1)\n",
    "        df['Count_PGT'] = df['Pseudo Ground Truth'].apply(lambda x: len(x))\n",
    "        df = df.set_index(['Subject','Relationship'])\n",
    "        return df\n",
    "\n",
    "    def add_recall_score(self, df):\n",
    "        df['Recall Prediction'] = np.random.randint(0, 100, df.shape[0])/100\n",
    "        return df\n",
    "\n",
    "\n",
    "    def load_dict(self):\n",
    "        try:\n",
    "            with open('data/dumps/id_dict.pkl', 'rb') as fp:\n",
    "                self.id_dict = pickle.load(fp)\n",
    "        except:\n",
    "            print (\"Creating a new Dictionary\")\n",
    "            self.id_dict = {}\n",
    "\n",
    "\n",
    "    def save_dict(self):\n",
    "        with self.lock:\n",
    "            old_dict = self.get_dict()\n",
    "            self.id_dict = {**self.id_dict, **old_dict}\n",
    "            with open('data/dumps/id_dict.pkl', 'wb') as fp:\n",
    "                pickle.dump(self.id_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Saved\")\n",
    "\n",
    "\n",
    "    def get_dict(self):\n",
    "        di = {}\n",
    "        with open('data/dumps/id_dict.pkl', 'rb') as fp:\n",
    "            di = pickle.load(fp)\n",
    "        return di\n",
    "\n",
    "\n",
    "    def Analyse(self, message, alt_url='https://api.rosette.com/rest/v1/'):\n",
    "        \"\"\" Run the example \"\"\"\n",
    "        # Create an API instance\n",
    "        api = API(user_key=\"89350904c7392a44f0f9019563be727a\", service_url=alt_url)\n",
    "\n",
    "        # Set selected API options.\n",
    "        # For more information on the functionality of these\n",
    "        # and other available options, see Rosette Features & Functions\n",
    "        # https://developer.rosette.com/features-and-functions#morphological-analysis-introduction\n",
    "\n",
    "        # api.set_option('modelType','perceptron') #Valid for Chinese and Japanese only\n",
    "\n",
    "        # Opening the ID Dictionary\n",
    "#         load_dict()\n",
    "        ### Will Close after Analysis of the document is completed\n",
    "\n",
    "        params = DocumentParameters()\n",
    "        relationships_text_data = wikipedia.page(message).content[:20000]\n",
    "        params[\"content\"] = relationships_text_data\n",
    "        rel = []\n",
    "        message_id = self.get_id(message)\n",
    "        message_split = message.split(\" \")\n",
    "        try:\n",
    "            RESULT = api.relationships(params)\n",
    "            #print(RESULT)\n",
    "            for r in RESULT['relationships']:\n",
    "                arg2_split = r['arg2'].split(\" \")\n",
    "                confidence = '?'\n",
    "                if \"confidence\" in r:\n",
    "                    confidence = str(round(r[\"confidence\"],2))\n",
    "                if any(s in arg2_split for s in message_split):\n",
    "                    if self.get_id(r['arg2']) == message_id:\n",
    "                        rel.append({'Relationship':r['predicate']+'^-1', 'Subject':r['arg2'], 'Object':r['arg1'], 'Confidence': confidence})\n",
    "                rel.append({'Relationship':r['predicate'],'Subject':r['arg1'],'Object':r['arg2'], 'Confidence': confidence})\n",
    "\n",
    "            ## Closing the ID Dict\n",
    "            self.save_dict()\n",
    "            ##\n",
    "            return rel, message_id\n",
    "        except RosetteException as exception:\n",
    "            print(exception)\n",
    "\n",
    "\n",
    "class HeatMaps(Thread):\n",
    "    def __init__(self, lock, relation='Educated at', eid=None, name=None, rel_dict={}):\n",
    "        Thread.__init__(self)\n",
    "        self.q1 = queue.Queue()\n",
    "        self.q2 = queue.Queue()\n",
    "        self.u = Utils()\n",
    "        self.lock = lock\n",
    "        self.rel_dict = rel_dict\n",
    "        self.eid = eid\n",
    "        self.message = name\n",
    "        self.error = None\n",
    "        self.relation = relation\n",
    "        self.inverse = True if \"^-1\" in relation else False\n",
    "        if name:\n",
    "            self.eid = self.u.get_id(name)\n",
    "        else:\n",
    "            self.message = self.u.id_to_name(eid)\n",
    "        self.start()\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        if self.eid not in self.rel_dict:\n",
    "            a = Thread(target = self.Analyse, args = ())\n",
    "            b = Thread(target = self.ground_truth, args = ())\n",
    "            a.start()\n",
    "            b.start()\n",
    "            a.join()\n",
    "            b.join()\n",
    "        self.matrix_block()\n",
    "\n",
    "\n",
    "    def Analyse(self):\n",
    "        \"\"\" Run the example \"\"\"\n",
    "        # Create an API instance\n",
    "        api = API(user_key=\"89350904c7392a44f0f9019563be727a\", service_url='https://api.rosette.com/rest/v1/')\n",
    "#         u = Utils()\n",
    "        params = DocumentParameters()\n",
    "        relationships_text_data = []\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                relationships_text_data = wikipedia.page(self.message).content[:20000]\n",
    "                break\n",
    "            except wikipedia.DisambiguationError as e:\n",
    "                print(self.eid, self.message)\n",
    "                nameclash = True\n",
    "                for n in e.options:\n",
    "                    if self.u.get_id(n) == self.eid:\n",
    "                        if n == self.message:\n",
    "                            pass\n",
    "                        else:\n",
    "                            self.message = n\n",
    "                            nameclash = False\n",
    "                            break\n",
    "                if nameclash:\n",
    "                    self.message = \" \"\n",
    "            except wikipedia.exceptions.PageError as e:\n",
    "                self.error = self.u.id_to_name(self.eid) + \" \" + str(e)\n",
    "                print (self.error)\n",
    "                break\n",
    "            \n",
    "        params[\"content\"] = relationships_text_data\n",
    "        rel = []\n",
    "        message_id = self.u.get_id(self.message)\n",
    "        message_split = self.message.split(\" \")\n",
    "        pred_list = []\n",
    "        try:\n",
    "            RESULT = []\n",
    "            with self.lock:\n",
    "                RESULT = api.relationships(params)\n",
    "            \n",
    "            args = ['arg1','arg2']\n",
    "            arg_to_split = 'arg2' if self.inverse else 'arg1'\n",
    "            args.remove(arg_to_split)\n",
    "            other_arg = args[0]\n",
    "            rel_to_compare = self.relation.split(\"^-1\")[0]\n",
    "                \n",
    "            for r in RESULT['relationships']:\n",
    "                if r['predicate'] == rel_to_compare:\n",
    "                    arg_split = r[arg_to_split].split(\" \") # Subject Split \n",
    "                    if any(s in arg_split for s in message_split): # Searching for alias names\n",
    "                        if self.u.get_id(r[arg_to_split]) == message_id:\n",
    "                            pred_list.append(r[other_arg])\n",
    "                            \n",
    "            self.q1.put(set(pred_list))\n",
    "        except RosetteException as exception:\n",
    "            print(exception)\n",
    "            self.q1.put(set(pred_list))\n",
    "\n",
    "\n",
    "    def ground_truth(self):\n",
    "#         u = Utils()\n",
    "        \n",
    "        pgt = set(self.u.ground_truth(self.relation, self.message))\n",
    "        self.q2.put(pgt)\n",
    "    \n",
    "    \n",
    "    def matrix_block(self):\n",
    "        if self.eid in self.rel_dict:\n",
    "            self.pgt = self.rel_dict[self.eid]['PGT']\n",
    "            self.extracted = self.rel_dict[self.eid]['Extracted']\n",
    "            self.contained = self.rel_dict[self.eid]['Contained']\n",
    "        else:\n",
    "            q1 = self.q1.get() # Extracted from API\n",
    "            q2 = self.q2.get() # PGT\n",
    "            #print(self.message, q1)\n",
    "            #print(self.message, q2)\n",
    "            self.pgt = len(q2)\n",
    "            self.extracted = len(q1)\n",
    "            q1 = [self.u.get_id(i) for i in q1]\n",
    "            q2 = [self.u.get_id(i) for i in q2]\n",
    "            #print(self.message, q1)\n",
    "            #print(self.message, q2)\n",
    "            count = 0\n",
    "            for i in q1:\n",
    "                if i in q2:\n",
    "                    count += 1\n",
    "            self.contained = count\n",
    "\n",
    "    def get_values(self):\n",
    "        if self.error:\n",
    "            raise Exception(self.error)\n",
    "        return [self.eid, self.message, self.extracted, self.contained, self.pgt]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Distribution(Thread):\n",
    "    def __init__(self, eid=None, name=None, lock=None, rel_dict={}):\n",
    "        Thread.__init__(self)\n",
    "        self.doc_len = None\n",
    "        self.u = Utils()\n",
    "        self.eid = eid\n",
    "        self.message = name\n",
    "        self.error = None\n",
    "        if name:\n",
    "            self.eid = self.u.get_id(name)\n",
    "        else:\n",
    "            self.message = self.u.id_to_name(eid)\n",
    "        if eid in rel_dict:\n",
    "            self.doc_len = rel_dict[eid]['Doc_Length']\n",
    "            return\n",
    "        self.start()\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                document = wikipedia.page(self.message).content\n",
    "                self.doc_len = len(document)\n",
    "                break\n",
    "            except wikipedia.DisambiguationError as e:\n",
    "                print(self.eid, self.message)\n",
    "                nameclash = True\n",
    "                for n in e.options:\n",
    "                    if self.u.get_id(n) == self.eid:\n",
    "                        if n == self.message:\n",
    "                            pass\n",
    "                        else:\n",
    "                            self.message = n\n",
    "                            nameclash = False\n",
    "                            break\n",
    "                if nameclash:\n",
    "                    self.message = \" \"\n",
    "            except wikipedia.exceptions.PageError as e:\n",
    "                self.error = self.u.id_to_name(self.eid) + \" \" + str(e)\n",
    "                print (self.error)\n",
    "                break\n",
    "    \n",
    "    def get_values(self):\n",
    "        if self.error:\n",
    "            raise Exception(self.error)\n",
    "        return [self.eid, self.message, self.doc_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:48:04.871480Z",
     "start_time": "2019-03-07T15:48:04.865468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:49:14.127826Z",
     "start_time": "2019-03-07T15:49:14.120813Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Analyse(message):\n",
    "    \"\"\" Run the example \"\"\"\n",
    "    # Create an API instance\n",
    "    alt_url='https://api.rosette.com/rest/v1/'\n",
    "    api = API(user_key=\"89350904c7392a44f0f9019563be727a\", service_url=alt_url)\n",
    "\n",
    "    params = DocumentParameters()\n",
    "    relationships_text_data = wikipedia.page(message).content[:20000]\n",
    "    params[\"content\"] = relationships_text_data\n",
    "    rel = []\n",
    "    message_id = u.get_id(message)\n",
    "    message_split = message.split(\" \")\n",
    "    try:\n",
    "        RESULT = api.relationships(params)\n",
    "\n",
    "        for r in RESULT['relationships']:\n",
    "            arg2_split = r['arg2'].split(\" \")\n",
    "            confidence = '?'\n",
    "            if \"confidence\" in r:\n",
    "                confidence = str(round(r[\"confidence\"],2))\n",
    "            if any(s in arg2_split for s in message_split):\n",
    "                if u.get_id(r['arg2']) == message_id:\n",
    "                    rel.append({'Relationship':r['predicate']+'^-1', 'Subject':r['arg2'], 'Object':r['arg1'], 'Confidence': confidence})\n",
    "            rel.append({'Relationship':r['predicate'],'Subject':r['arg1'],'Object':r['arg2'], 'Confidence': confidence})\n",
    "\n",
    "        return rel, message_id\n",
    "    except RosetteException as exception:\n",
    "        print(exception)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:49:44.737597Z",
     "start_time": "2019-03-07T15:49:43.693409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "message = 'Diorama (band)'\n",
    "alt_url='https://api.rosette.com/rest/v1/'\n",
    "api = API(user_key=\"89350904c7392a44f0f9019563be727a\", service_url=alt_url)\n",
    "\n",
    "params = DocumentParameters()\n",
    "relationships_text_data = wikipedia.page(message).content[:20000]\n",
    "params[\"content\"] = relationships_text_data\n",
    "rel = []\n",
    "message_id = u.get_id(message)\n",
    "message_split = message.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:49:45.632225Z",
     "start_time": "2019-03-07T15:49:44.739512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RESULT = api.relationships(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:51:44.417429Z",
     "start_time": "2019-03-07T15:51:43.777109Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diorama is a German electropop band. The name of the band is a metaphor which represents their notion of music as an artistic form of expression.\\n\\n\\n== History ==\\nDiorama was founded in 1996 as a musical project of Torben Wendt. Torben’s music was soon recognized by Adrian Hates of Diary of Dreams, so with his support and the support of Rainer Assmann (Daf/ Fad Gadget), a debut-album “Pale” was released in 1999. It was received very well both by the critics and the audience.In 2000, Torben’s friend Felix Marc joined Diorama as a keyboard player, co-producer and backing vocalist. The second album “Her Liquid Arms” was released in April 2001. Despite its stronger rhythms and more forceful electronic sounds, the music preserved its distinctive atmosphere, established with the first album. The song “Advance” became one of the leading club hits and the band was becoming increasingly popular. The second album was followed by club-oriented single “Device” (December, 2001).\\nBassist Bernard Le Sigue joined the band the following year, and together with Torben and Felix saw the release of the third album, named “The Art of Creating Confusing Spirits”, the album was released in October 2002. During November and December of the same year, Diorama supported Diary of Dreams on tour.\\n\\nAfter a long break and another addition to the band’s line-up (guitar player Sash Fiddler joining in 2003), the long-awaited fourth album \"Amaroid\" was released in April 2005. For the promotion of the new album, the band joined VNV Nation, on their “Formation” tour. In October 2005, Diorama released two more albums:  A re-release of their first album “Pale”, with three new songs (“Don’t Be There”, “You and Ice” and “Crop of Illusions”); and  “Re-Pale” – a collection of new versions of earlier songs, remixes and some previously unreleased songs. At the same time, the band went on their first headline tour throughout Germany.\\nAt the end of 2006, Bernard Le Sigue left the band. On 23 February 2007, a new single was released: “Synthesize Me”, a prelude for the next album, which was released 4 weeks later. “A Different Life” can be characterized as a criticism of the society ruled by artificial, deviant system of values. With his lyrics, Torben portrayed the revolt of the individual against the imposed principles and general degradation of true values and virtues.\\n\"Cubed\" is their seventh studio album (released on 19 March 2010).\\nThe figurative picture of a cube is the guiding theme of the album - a confined area serving as a living space be it as a stage, as a prison or as a shelter.  This concept consequently  features throughout the band\\'s artwork and stage setting.\\nThis album climbed in German Alternative Charts (DAC of week 16/2010) to the top position.\\nThe members of Diorama have collaborated with a number of bands, including Diary of Dreams, Angels & Agony, Painbastard, Klangstabil and Frozen Plasma.\\n\\n\\n== Style ==\\nDiorama are often labeled as \"EBM\", “Electro-Pop”, “Future Pop” or “Darkwave” (particularity on the albums \"Her Liquid Arms\" and \"Pale\"). The melodies can be fast-paced and backed by rhythms and can be melancholic ballads. The diapason of the lyrics’ motifs takes inspiration from the inner world of the writer himself (Torben Wendt) and also his surroundings. The lyrics are written in a dark, kafkian style and are often ambiguous. Distinctive playing with words and metaphors is one of the prominent virtues of Diorama’s artistic opus.\\n\\n\\n== Band members ==\\n\\n\\n=== Current ===\\n\\nTorben Wendt – lyrics, vocals, keys, percussion\\nFelix Marc – co-production, keys, vocals\\nZura Nakamura – guitars\\nMarkus \"Marquess\" Halter – drums\\n\\n\\n=== Former ===\\nBernard Le Sigue – bass\\nSash Fiddler – guitars\\n\\n\\n== Discography ==\\n\\n\\n=== Albums ===\\nPale (1999)\\nHer Liquid Arms (2001)\\nThe Art of Creating Confusing Spirits (2003)\\nAmaroid (2005)\\nRe-Pale (2005)\\nPale re-release (2005)\\nA Different Life (2007)\\nCubed (2010)\\nEven the Devil Doesn\\'t Care (2013)\\nZero Soldier Army (2016)\\n\\n\\n=== Singles ===\\nDevice (2001)\\nSynthesize me (2007)\\nChild of Entertainment (2010)\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nOfficial website\\nDiorama on MySpace\\nAccession Records (German)\\nHome of the Diorama Lemmings\\nAmaroid - a tribute to the band diorama'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.page('Diorama (band)').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:52:06.527941Z",
     "start_time": "2019-03-07T15:52:06.171239Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_id('Diorama (band)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:50:45.668551Z",
     "start_time": "2019-03-07T15:50:45.664530Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diorama'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.id_to_name('Q207697')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:49:37.381355Z",
     "start_time": "2019-03-07T15:49:37.375372Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:52:02.708836Z",
     "start_time": "2019-03-07T15:52:02.704846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_id(message):\n",
    "    API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "    query = message\n",
    "    params = {\n",
    "        'action': 'wbsearchentities',\n",
    "        'format': 'json',\n",
    "        'language': 'en',\n",
    "        'search': query\n",
    "    }\n",
    "    r = requests.get(API_ENDPOINT, params = params)\n",
    "    try:\n",
    "        return (r.json()['search'][0]['id'])\n",
    "    except Exception:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Analyse(message, alt_url='https://api.rosette.com/rest/v1/'):\n",
    "    \"\"\" Run the example \"\"\"\n",
    "    # Create an API instance\n",
    "    api = API(user_key=\"89350904c7392a44f0f9019563be727a\", service_url=alt_url)\n",
    "\n",
    "    # Set selected API options.\n",
    "    # For more information on the functionality of these\n",
    "    # and other available options, see Rosette Features & Functions\n",
    "    # https://developer.rosette.com/features-and-functions#morphological-analysis-introduction\n",
    "\n",
    "    # api.set_option('modelType','perceptron') #Valid for Chinese and Japanese only\n",
    "    params = DocumentParameters()\n",
    "    relationships_text_data = wikipedia.page(message).content[:20000]\n",
    "    params[\"content\"] = relationships_text_data\n",
    "    rel = []\n",
    "    gt = []\n",
    "    message_id = get_id(message)\n",
    "    try:\n",
    "        RESULT = api.relationships(params)\n",
    "        #print(RESULT)\n",
    "        for r in RESULT['relationships']:\n",
    "#             gt += add_ground_truth(r['predicate'], r['arg1'], r['arg2'])\n",
    "            confidence = -1\n",
    "            if \"confidence\" in r:\n",
    "                confidence = r[\"confidence\"]\n",
    "            if get_id(r['arg2']) == message_id:\n",
    "                rel.append({'Relationship':r['predicate']+'^-1', 'Subject':r['arg2'], 'Object':r['arg1'], 'Confidence': confidence})\n",
    "            rel.append({'Relationship':r['predicate'],'Subject':r['arg1'],'Object':r['arg2'], 'Confidence': confidence})\n",
    "        return rel, message_id\n",
    "    except RosetteException as exception:\n",
    "        print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "sample_message = \"FLIR Systems is headquartered in Oregon and produces thermal imaging, night vision, and infrared cameras and sensor systems.  According to the SEC’s order instituting a settled administrative proceeding, FLIR entered into a multi-million dollar contract to provide thermal binoculars to the Saudi government in November 2008.  Timms and Ramahi were the primary sales employees responsible for the contract, and also were involved in negotiations to sell FLIR’s security cameras to the same government officials.  At the time, Timms was the head of FLIR’s Middle East office in Dubai. After that, Timms joined Google.\"\n",
    "result = Analyse(sample_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_message = \"Steve Jobs\" #\"Andrew Ng\"\n",
    "result, message_id = Analyse(sample_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['Subject','Relationship','Object','Confidence'])\n",
    "# print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_df = df[df['Subject'].apply(lambda row: get_id(row)) == message_id]\n",
    "other_df = df[~df.isin(main_df).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "####################### NEW ####################\n",
    "e1Grp = df.sort_values('Object', ascending=True).drop_duplicates().groupby(['Subject','Relationship']).agg(lambda x: list(x)).reset_index()\n",
    "rows = []\n",
    "_ = e1Grp.apply(lambda row: [rows.append([row['Subject'],row['Relationship'], e2, e3]) for e2,e3 in zip(row.Object, row.Confidence)], axis=1)\n",
    "e1Grp = pd.DataFrame(rows, columns=e1Grp.columns).set_index(['Subject','Relationship'])\n",
    "\n",
    "# e1Grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_df['RScore'] = np.random.randint(0, 100, main_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_df = main_df[[c for c in main_df if c not in ['Confidence']] + ['Confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(main_df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_df = main_df.sort_values('Object', ascending=True).drop_duplicates().groupby(['Subject','Relationship']).agg(lambda x: list(x))\n",
    "main_df['Count'] = main_df['Object'].apply(lambda x: len(x))\n",
    "# print(main_df)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "other_df = other_df.sort_values('Object', ascending=True).drop_duplicates().groupby(['Subject','Relationship']).agg(lambda x: list(x))\n",
    "other_df['Count'] = other_df['Object'].apply(lambda x: len(x))\n",
    "# print(other_df)\n",
    "other_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Pseudo Ground Truth from Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# query = \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "#   ?item wdt:P112 wd:Q19837.\n",
    "#   SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "# }\"\"\"\n",
    "\n",
    "\n",
    "def get_results(query, value, endpoint_url=\"https://query.wikidata.org/sparql\"):\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setQuery(query%value)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "def ground_truth(relation, subject):\n",
    "    results = []\n",
    "    gt = []\n",
    "    try:\n",
    "        results = [get_results(query, get_id(subject)) for query in query_dict[relation]]\n",
    "        for result in results:\n",
    "            for r in result[\"results\"][\"bindings\"]:\n",
    "                gt.append(r['itemLabel']['value'])\n",
    "    except:\n",
    "        print (relation, subject)\n",
    "#         gt = ['Unknown']\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_dict = {'Organization Founded By^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          ?item wdt:P112 wd:%s.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                           ],\n",
    "              'Organization Founded By':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P112 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                        ],\n",
    "              'Organization Headquarters':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P159 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                          ],\n",
    "              'Organization Subsidiary Of^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P355 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                              ],\n",
    "              'Organization Subsidiary Of':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          ?item wdt:P355 wd:%s.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                           ],\n",
    "              'Organization top employees':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P169 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\", # CEO\n",
    "                                            \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          wd:%s wdt:P488 ?item.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\" # Chairperson\n",
    "                                            ],\n",
    "              'Person Employee or Member of^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                          ?item wdt:P108 wd:%s.\n",
    "                                          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                        }\"\"\"\n",
    "                                                ],\n",
    "              'Person Employee or Member of':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P108 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                            ],\n",
    "              'Person Place of Birth':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P19 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                      ],\n",
    "              'Person Current and Past Location of Residence':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P551 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                                              ],\n",
    "              'Person Parents':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P22 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\", #Father\n",
    "                                \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P25 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\", #Mother\n",
    "                                \"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P1038 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\" #Relative (Adopted Parents?)\n",
    "                                # Shall we include stepparents??\n",
    "                               ],\n",
    "              'Person Parents^-1':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P40 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                  ],\n",
    "              'Person Siblings':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P3373 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                                ],\n",
    "              'Person Spouse':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P26 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                              ],\n",
    "              'Citizen of':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P27 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                           ],\n",
    "              'Educated at':[\"\"\"SELECT ?item ?itemLabel WHERE {\n",
    "                                              wd:%s wdt:P69 ?item.\n",
    "                                              SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "                                            }\"\"\"\n",
    "                            ]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "results = [get_results(endpoint_url, query, get_id(\"Steve Jobs\")) for query in query_dict['Educated at']]\n",
    "\n",
    "gt = []\n",
    "for result in results:\n",
    "    for r in result[\"results\"][\"bindings\"]:\n",
    "        gt.append(r['itemLabel']['value'])\n",
    "print (len(gt))\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp['Relationship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = main_df.reset_index()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp['Ground Truth'] = temp.apply(lambda row: ground_truth(row['Relationship'], row['Subject']), axis=1)\n",
    "temp['Count_GT'] = temp['Ground Truth'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp.set_index(['Subject','Relationship'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = {'33':33}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f1():\n",
    "    global a\n",
    "    a['33'] = 33\n",
    "    print (\"B\\n\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f2():\n",
    "    global a\n",
    "    with open('data.p', 'rb') as fp:\n",
    "        a = pickle.load(fp)\n",
    "    a['1222'] = 1222\n",
    "    print (\"A\\n\",a)\n",
    "    f1()\n",
    "    with open('data.p', 'wb') as fp:\n",
    "        pickle.dump(a, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"C\\n\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f(batch_size=1,num_workers=1,shuffle=None,):\n",
    "    print(batch_size)\n",
    "    print(shuffle)\n",
    "    print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root = \"./dataset/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:22:04.731395Z",
     "start_time": "2019-03-13T15:22:03.959055Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:23:20.243134Z",
     "start_time": "2019-03-13T15:23:20.237888Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_results(query, endpoint_url=\"https://query.wikidata.org/sparql\"):\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:24:24.035932Z",
     "start_time": "2019-03-13T15:23:20.664835Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "EndPointInternalError",
     "evalue": "EndPointInternalError: endpoint returned code 500 and response. \n\nResponse:\nb'SPARQL-QUERY: queryStr=SELECT ?person (COUNT(*) AS ?cnt) WHERE {\\n           hint:Query hint:optimizer \"None\"\\n\\n           {SELECT ?person WHERE {\\n             ?person wdt:P31 wd:Q5.\\n           }}.\\n\\n           ?person ?prop ?thing\\n     } GROUP BY ?person\\n     ORDER BY DESC(?cnt)\\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:293)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:679)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:271)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:338)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:49)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\SPARQLWrapper\\Wrapper.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnFormat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    641\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 642\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Server Error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEndPointInternalError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-983074552c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-f789e5cd4176>\u001b[0m in \u001b[0;36mget_results\u001b[1;34m(query, endpoint_url)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msparql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msparql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetReturnFormat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJSON\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msparql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\SPARQLWrapper\\Wrapper.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mQueryResult\u001b[0m\u001b[1;33m}\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         \"\"\"\n\u001b[1;32m--> 798\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mQueryResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mqueryAndConvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\SPARQLWrapper\\Wrapper.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    774\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mEndPointInternalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEndPointInternalError\u001b[0m: EndPointInternalError: endpoint returned code 500 and response. \n\nResponse:\nb'SPARQL-QUERY: queryStr=SELECT ?person (COUNT(*) AS ?cnt) WHERE {\\n           hint:Query hint:optimizer \"None\"\\n\\n           {SELECT ?person WHERE {\\n             ?person wdt:P31 wd:Q5.\\n           }}.\\n\\n           ?person ?prop ?thing\\n     } GROUP BY ?person\\n     ORDER BY DESC(?cnt)\\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:293)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:679)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:271)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:338)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:49)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n'"
     ]
    }
   ],
   "source": [
    "get_results(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:23:04.404513Z",
     "start_time": "2019-03-13T15:23:04.397084Z"
    }
   },
   "outputs": [],
   "source": [
    "query = '''SELECT ?person (COUNT(*) AS ?cnt) WHERE {\n",
    "           hint:Query hint:optimizer \"None\"\n",
    "\n",
    "           {SELECT ?person WHERE {\n",
    "             ?person wdt:P31 wd:Q5.\n",
    "           }}.\n",
    "\n",
    "           ?person ?prop ?thing\n",
    "     } GROUP BY ?person\n",
    "     ORDER BY DESC(?cnt)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
